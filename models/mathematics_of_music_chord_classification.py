{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-12-17T04:19:46.686960Z\",\"iopub.execute_input\":\"2022-12-17T04:19:46.687277Z\",\"iopub.status.idle\":\"2022-12-17T04:19:46.693996Z\",\"shell.execute_reply.started\":\"2022-12-17T04:19:46.687239Z\",\"shell.execute_reply\":\"2022-12-17T04:19:46.692978Z\"}}\n#import package\nimport os\nimport IPython\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.io import wavfile\nfrom scipy.fft import fft, fftfreq\nfrom scipy.signal import spectrogram, find_peaks\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-12-17T04:19:46.695682Z\",\"iopub.execute_input\":\"2022-12-17T04:19:46.696147Z\",\"iopub.status.idle\":\"2022-12-17T04:19:46.738625Z\",\"shell.execute_reply.started\":\"2022-12-17T04:19:46.696113Z\",\"shell.execute_reply\":\"2022-12-17T04:19:46.737505Z\"}}\n# Our hearing range is commonly 20 Hz to 20 kHz\n\n#label frequency with correspnding note\ncurr_freq = 55\nfreq_list = []\n\n# I want to calculate 8 octaves of notes. Each octave has 12 notes. Looping for 96 steps:\nfor i in range(96): \n    freq_list.append(curr_freq)\n    curr_freq *= np.power(2, 1/12) # Multiplying by 2^(1/12)\n\n#reshaping and creating dataframe\nfreq_array = np.reshape(np.round(freq_list,1), (8, 12))\ncols = [\"A\", \"A#\", \"B\", \"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\"]\ndf_note_freqs = pd.DataFrame(freq_array, columns=cols)\nprint(\"NOTE FREQUENCIES IN WESTERN MUSIC\")\ndf_note_freqs.head(10)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-12-17T04:19:46.740643Z\",\"iopub.execute_input\":\"2022-12-17T04:19:46.740954Z\",\"iopub.status.idle\":\"2022-12-17T04:19:46.757668Z\",\"shell.execute_reply.started\":\"2022-12-17T04:19:46.740921Z\",\"shell.execute_reply\":\"2022-12-17T04:19:46.756533Z\"}}\npath_1 = \"../input/musical-instrument-chord-classification/Audio_Files/Major/Major_0.wav\"\npath_2 = \"../input/musical-instrument-chord-classification/Audio_Files/Minor/Minor_169.wav\"\npath_3 = \"../input/musical-instrument-chord-classification/Audio_Files/Major/Major_111.wav\"\nIPython.display.Audio(path_1, rate = 44100) #A C E major\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-12-17T04:19:46.759173Z\",\"iopub.execute_input\":\"2022-12-17T04:19:46.759522Z\",\"iopub.status.idle\":\"2022-12-17T04:19:46.773364Z\",\"shell.execute_reply.started\":\"2022-12-17T04:19:46.759481Z\",\"shell.execute_reply\":\"2022-12-17T04:19:46.772674Z\"}}\nIPython.display.Audio(path_2, rate = 44100) #minor\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-12-17T04:19:46.775498Z\",\"iopub.execute_input\":\"2022-12-17T04:19:46.775974Z\",\"iopub.status.idle\":\"2022-12-17T04:19:46.791921Z\",\"shell.execute_reply.started\":\"2022-12-17T04:19:46.775931Z\",\"shell.execute_reply\":\"2022-12-17T04:19:46.788355Z\"}}\nIPython.display.Audio(path_3, rate = 44100) #major\n\n# %% [markdown]\n# ## 1.4. Detection of Harmonic Frequencies\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-12-17T04:19:46.793269Z\",\"iopub.execute_input\":\"2022-12-17T04:19:46.793596Z\",\"iopub.status.idle\":\"2022-12-17T04:19:46.802505Z\",\"shell.execute_reply.started\":\"2022-12-17T04:19:46.793557Z\",\"shell.execute_reply\":\"2022-12-17T04:19:46.801745Z\"}}\n# I would like to create a method so that I can use in the next section\n# The method will read sound file, apply Fourier, find peak frequencies and return\n# Input: path of the sound file\n# Output: Frequency peaks\n# print_peaks = true to plot peaks\n\ndef find_harmonics(path, print_peaks=False):\n    fs, X = wavfile.read(path)\n    N = len(X)\n    X_F = fft(X)\n    X_F_onesided = 2.0/N * np.abs(X_F[0:N//2])\n    freqs = fftfreq(N, 1/fs)[:N//2]\n    freqs_50_index = np.abs(freqs - 50).argmin()\n    \n    h = X_F_onesided.max()*5/100\n    peaks, _ = find_peaks(X_F_onesided, distance=10, height = h)\n    peaks = peaks[peaks>freqs_50_index]\n    harmonics = np.round(freqs[peaks],2)\n    \n    if print_peaks:\n        i = peaks.max() + 100\n        plt.plot(freqs[:i], X_F_onesided[:i])\n        plt.plot(freqs[peaks], X_F_onesided[peaks], \"x\")\n        plt.xlabel('Frequency [Hz]')\n        plt.show()\n    return harmonics\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-12-17T04:19:46.803776Z\",\"iopub.execute_input\":\"2022-12-17T04:19:46.804127Z\",\"iopub.status.idle\":\"2022-12-17T04:19:47.033903Z\",\"shell.execute_reply.started\":\"2022-12-17T04:19:46.804093Z\",\"shell.execute_reply\":\"2022-12-17T04:19:47.032883Z\"}}\n# Another example to check if method is working correctly\npath = \"../input/musical-instrument-chord-classification/Audio_Files/Minor/Minor_169.wav\"\n\nharmonics_2 = find_harmonics(path, print_peaks=True)\nprint(\"Harmonics: {}\".format(np.round(harmonics_2)))\n\n#map the harmonic frequency to the table we build before to determine the chord\n\n# %% [markdown]\n# # 2. Importing Dataset\n\n# %% [markdown]\n# In this section, I will create a DataFrame so that I can analyze all the sound data together. There are more than 800 wav files. First, I will loop through all the files and find harmonics. I will save chord type, file name and all harmonics for each file. I will also save minimum & maximum harmonics and the number of harmonics for easier analysis. After the loop, I will convert it to a DataFrame.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-12-17T04:19:47.035048Z\",\"iopub.execute_input\":\"2022-12-17T04:19:47.035296Z\",\"iopub.status.idle\":\"2022-12-17T04:19:54.761271Z\",\"shell.execute_reply.started\":\"2022-12-17T04:19:47.035265Z\",\"shell.execute_reply\":\"2022-12-17T04:19:54.760473Z\"}}\npath = \"/kaggle/input/musical-instrument-chord-classification/Audio_Files\"\ndata = []\nmax_harm_length = 0 # i will keep track of max harmonic length for naming columns\n\nfor dirname, _, filenames in os.walk(path):\n    for filename in filenames:\n        foldername = os.path.basename(dirname)\n        full_path = os.path.join(dirname, filename)\n        freq_peaks = find_harmonics(full_path)\n        \n        max_harm_length = max(max_harm_length, len(freq_peaks))\n        \n        cur_data = [foldername, filename]\n        cur_data.extend([freq_peaks.min(), freq_peaks.max(), len(freq_peaks)])\n        cur_data.extend(freq_peaks)\n        \n        data.append(cur_data)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-12-17T04:19:54.763289Z\",\"iopub.execute_input\":\"2022-12-17T04:19:54.763571Z\",\"iopub.status.idle\":\"2022-12-17T04:19:54.800030Z\",\"shell.execute_reply.started\":\"2022-12-17T04:19:54.763538Z\",\"shell.execute_reply\":\"2022-12-17T04:19:54.799053Z\"}}\n# Column Names for DataFrame:\ncols = [\"Chord Type\", \"File Name\", \"Min Harmonic\", \"Max Harmonic\", \"# of Harmonics\"]\nfor i in range(max_harm_length):\n    cols.append(\"Harmonic {}\".format(i+1))\n\n# Creating DataFrame\ndf = pd.DataFrame(data, columns=cols)\ndf.head()\n\n# %% [markdown]\n# # 3. Data Exploration\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-12-17T04:19:54.801712Z\",\"iopub.execute_input\":\"2022-12-17T04:19:54.801979Z\",\"iopub.status.idle\":\"2022-12-17T04:19:54.816563Z\",\"shell.execute_reply.started\":\"2022-12-17T04:19:54.801947Z\",\"shell.execute_reply\":\"2022-12-17T04:19:54.815556Z\"}}\ndf[\"Chord Type\"].value_counts()\n\n# %% [markdown]\n# ## 3.1. Min and Max Harmonics\n\n# %% [markdown]\n# ## 3.2. Number of Harmonics\n\n# %% [markdown]\n# In the column \"# of Harmonics\", I have information that how many harmonic values are not null in that row. For example if \"# of Harmonics\" is 12, that row will have values from \"Harmonic 1\" to \"Harmonic 12\", but after \"Harmonic 13\" we will see NaN values. This \"# of Harmonics\" column will not be directly related to my classification model but will make it easier to analyze other columns.\n# \n# Using describe method on \"# of harmonics\", I see that\n# * min is 8 --> every row at least 8 harmonics value\n# * max is 38 --> last column will be \"Harmonic 38\"\n# * starting with column \"Harmonic 9\", there will be NaN values\n# * since harmonics are ordered, missing values will increase with each column\n# * the mean value for the number of harmonics is 20\n# \n# Looking at the number of missing values, I know that I will drop most of the columns. Harmonics bigger than 20 are gone. The first 8 harmonics are absolutely important. But I am not sure about the harmonics in between. I have to make more exploration to decide for them.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-12-17T04:19:54.818437Z\",\"iopub.execute_input\":\"2022-12-17T04:19:54.819253Z\",\"iopub.status.idle\":\"2022-12-17T04:19:54.834382Z\",\"shell.execute_reply.started\":\"2022-12-17T04:19:54.819195Z\",\"shell.execute_reply\":\"2022-12-17T04:19:54.833475Z\"}}\ndf[\"# of Harmonics\"].describe()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-12-17T04:19:54.835484Z\",\"iopub.execute_input\":\"2022-12-17T04:19:54.835704Z\",\"iopub.status.idle\":\"2022-12-17T04:19:54.848081Z\",\"shell.execute_reply.started\":\"2022-12-17T04:19:54.835677Z\",\"shell.execute_reply\":\"2022-12-17T04:19:54.847184Z\"}}\nprint(\"Number of Missing values:\")\nmiss_values = df.isnull().sum().sort_values(ascending=False)\nmiss_values[miss_values>0]\n\n# %% [markdown] {\"execution\":{\"iopub.status.busy\":\"2022-02-23T08:37:49.951755Z\",\"iopub.execute_input\":\"2022-02-23T08:37:49.952252Z\",\"iopub.status.idle\":\"2022-02-23T08:37:49.956186Z\",\"shell.execute_reply.started\":\"2022-02-23T08:37:49.952215Z\",\"shell.execute_reply\":\"2022-02-23T08:37:49.955048Z\"}}\n# ## 3.3. Feature Engineering on Harmonics\n\n# %% [markdown]\n# Let's start exploring harmonics. \"Harmonic 1\" is the same column as \"Min Harmonic\" since harmonics are ordered. So I will start with \"Harmonic 2\". When I plotted the distribution of Harmonic 2 with hue Chord Type, I can't see a direct relationship between Harmonic 2 and Chord. But I have an idea. I already know that difference between Major and Minor comes from the intervals. And the frequency of notes increases on a logarithmic scale. If I divide Harmonic 2 by Harmonic 1, I can obtain the first interval.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-12-17T04:19:54.849645Z\",\"iopub.execute_input\":\"2022-12-17T04:19:54.849915Z\",\"iopub.status.idle\":\"2022-12-17T04:19:54.855179Z\",\"shell.execute_reply.started\":\"2022-12-17T04:19:54.849880Z\",\"shell.execute_reply\":\"2022-12-17T04:19:54.854233Z\"}}\ndf_original = df.copy() # Keeping original of df, I may need later\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-12-17T04:19:54.856624Z\",\"iopub.execute_input\":\"2022-12-17T04:19:54.856925Z\",\"iopub.status.idle\":\"2022-12-17T04:19:54.868258Z\",\"shell.execute_reply.started\":\"2022-12-17T04:19:54.856886Z\",\"shell.execute_reply\":\"2022-12-17T04:19:54.867627Z\"}}\ndf[\"Interval 1\"] = df[\"Harmonic 2\"].div(df[\"Harmonic 1\"], axis=0)\n\n# %% [markdown]\n# I'm really happy with the distribution of Interval 1. At last, we have data that changes with Chord Type. I will continue to calculate intervals using a loop. There are 38 harmonics but we already know that there are a huge amount of missing values for higher harmonics. So, I will loop for the first 20 intervals. For each interval, I will calculate the ratio of the current harmonic to the previous one.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-12-17T04:19:54.869715Z\",\"iopub.execute_input\":\"2022-12-17T04:19:54.869939Z\",\"iopub.status.idle\":\"2022-12-17T04:19:54.897810Z\",\"shell.execute_reply.started\":\"2022-12-17T04:19:54.869912Z\",\"shell.execute_reply\":\"2022-12-17T04:19:54.896788Z\"}}\ndf = df_original.copy() # refreshing df\n\nfor i in range(1,21):\n    curr_interval = \"Interval {}\".format(i)\n    curr_harm = \"Harmonic {}\".format(i+1)\n    prev_harm = \"Harmonic {}\".format(i)\n    df[curr_interval] = df[curr_harm].div(df[prev_harm], axis=0)\n    \ndf.head()\ndf['File Name'].to_csv('link.csv')\n\n# %% [markdown]\n# Looking at the huge plot of intervals:\n# * The first 4 interval looks interesting and I will use them in my model.\n# * After interval 13, the variable loses its importance completely.\n# * Starting from interval 8, there are missing values. I will most probably drop these intervals.\n# * Interval 5, 6 and 7 have no missing values, I will decide for them later.\n# \n# So far, we have analyzed the interval between the consecutive harmonics. What about total interval until specific harmonic? I mean the interval between the specific harmonic and the first harmonic. I will plot them using a loop again.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-12-17T04:19:54.899101Z\",\"iopub.execute_input\":\"2022-12-17T04:19:54.899374Z\",\"iopub.status.idle\":\"2022-12-17T04:19:57.001244Z\",\"shell.execute_reply.started\":\"2022-12-17T04:19:54.899340Z\",\"shell.execute_reply\":\"2022-12-17T04:19:57.000320Z\"}}\nfig, axes = plt.subplots(4, 3, figsize=(12, 8))\nfor i in range(2,14):\n    curr_interval = \"Interval {}_1\".format(i)\n    curr_harm = \"Harmonic {}\".format(i)\n    df[curr_interval] = df[curr_harm].div(df[\"Harmonic 1\"], axis=0)\n    \n    plt.subplot(4, 3, i-1)\n    plt.gca().set_title(\"Interval Btw H{} & H1\".format(i))\n    sns.kdeplot(data=df, x=curr_interval, hue=\"Chord Type\", shade=True)\nfig.tight_layout()\nplt.show()\n\n# %% [markdown]\n# # 4. Model Building\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-12-17T04:19:57.002589Z\",\"iopub.execute_input\":\"2022-12-17T04:19:57.002935Z\",\"iopub.status.idle\":\"2022-12-17T04:19:57.008996Z\",\"shell.execute_reply.started\":\"2022-12-17T04:19:57.002891Z\",\"shell.execute_reply\":\"2022-12-17T04:19:57.007939Z\"}}\n# importing packages\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n# %% [markdown]\n# ## 4.1. Preprocessing Data\n\n# %% [markdown]\n# There is just one step left before training the classification model. Since the Chord Type column is categorical and consists of strings, I will replace \"Major\" with 1 and \"Minor\" with 0. Finally, select columns that I will use in training and split the data into training and validation sets. I used test size as %40.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-12-17T04:19:57.012022Z\",\"iopub.execute_input\":\"2022-12-17T04:19:57.012291Z\",\"iopub.status.idle\":\"2022-12-17T04:19:57.033100Z\",\"shell.execute_reply.started\":\"2022-12-17T04:19:57.012259Z\",\"shell.execute_reply\":\"2022-12-17T04:19:57.032178Z\"}}\ndf[\"Chord Type\"] = df[\"Chord Type\"].replace(\"Major\", 1)\ndf[\"Chord Type\"] = df[\"Chord Type\"].replace(\"Minor\", 0)\n\ncolumns = [\"Interval 1\", \"Interval 2\", \"Interval 3\", \"Interval 4\"]\ncolumns.extend([\"Interval 4_1\", \"Interval 5_1\", \"Interval 6_1\"])\ntrain_X, val_X, train_y, val_y = train_test_split(df[columns], df[\"Chord Type\"], test_size=0.40, random_state=0)\n\ntrain_X.head()\n\n#output validation\nval_X.to_csv('val_X.csv')\n\n# %% [markdown]\n# ## 4.2. Model Selection\n\n# %% [markdown]\n# In order to select a classification model, I will try 6 different models in this section and compare their cross validation score.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-12-17T04:19:57.034504Z\",\"iopub.execute_input\":\"2022-12-17T04:19:57.034740Z\",\"iopub.status.idle\":\"2022-12-17T04:19:59.136490Z\",\"shell.execute_reply.started\":\"2022-12-17T04:19:57.034711Z\",\"shell.execute_reply\":\"2022-12-17T04:19:59.135372Z\"}}\nknn = KNeighborsClassifier()\ndtc = DecisionTreeClassifier(random_state=0)\nrfc = RandomForestClassifier(random_state=0)\n\nscore_knn = cross_val_score(knn, train_X, train_y, cv=10).mean()\nscore_dtc = cross_val_score(dtc, train_X, train_y, cv=10).mean()\nscore_rfc = cross_val_score(rfc, train_X, train_y, cv=10).mean()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-12-17T04:19:59.137975Z\",\"iopub.execute_input\":\"2022-12-17T04:19:59.138239Z\",\"iopub.status.idle\":\"2022-12-17T04:19:59.144978Z\",\"shell.execute_reply.started\":\"2022-12-17T04:19:59.138201Z\",\"shell.execute_reply\":\"2022-12-17T04:19:59.144099Z\"}}\nprint(\"Cross Val Score for KNeighbors Classifier: {:.2f}\".format(score_knn))\nprint(\"Cross Val Score for Decision Tree Classifier: {:.2f}\".format(score_dtc))\nprint(\"Cross Val Score for Random Forest Classifier: {:.2f}\".format(score_rfc))\n\n# %% [markdown]\n# ## 4.3. Model Training and Prediction\n\n# %% [markdown]\n# In the previous section, I tried 6 different models and Random Forest Classifier works really well with my dataset. I obtained 0.92 success rate with this model. After Random Forest Classifier, Decision Tree Classifier obtained %90 and KNeighbors Classifier obtained %83 success rate. \n# \n# Now, I will continue with Random Forest Classifier. First, I will train my model with the training dataset and then make a prediction on the validation dataset to see the accuracy.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-12-17T04:19:59.146295Z\",\"iopub.execute_input\":\"2022-12-17T04:19:59.146573Z\",\"iopub.status.idle\":\"2022-12-17T04:19:59.366473Z\",\"shell.execute_reply.started\":\"2022-12-17T04:19:59.146540Z\",\"shell.execute_reply\":\"2022-12-17T04:19:59.365282Z\"}}\n# defining my classifier RF\nrf_classifier = RandomForestClassifier(random_state=0)\nrf_classifier.fit(train_X, train_y) # training classifier\nrf_pred_y = rf_classifier.predict(val_X) # making prediction on validation\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-12-17T04:19:59.367953Z\",\"iopub.execute_input\":\"2022-12-17T04:19:59.368220Z\",\"iopub.status.idle\":\"2022-12-17T04:19:59.388562Z\",\"shell.execute_reply.started\":\"2022-12-17T04:19:59.368188Z\",\"shell.execute_reply\":\"2022-12-17T04:19:59.387507Z\"}}\n# defining my classifier KN\nkn_classifier = KNeighborsClassifier(n_neighbors=3)\nkn_classifier.fit(train_X, train_y) # training classifier\nkn_pred_y = kn_classifier.predict(val_X) # making prediction on validation\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-12-17T04:19:59.389578Z\",\"iopub.execute_input\":\"2022-12-17T04:19:59.389863Z\",\"iopub.status.idle\":\"2022-12-17T04:19:59.400626Z\",\"shell.execute_reply.started\":\"2022-12-17T04:19:59.389831Z\",\"shell.execute_reply\":\"2022-12-17T04:19:59.399502Z\"}}\n'RF accuracy'\nrf_cm = confusion_matrix(val_y, rf_pred_y)\nrf_acc = accuracy_score(val_y, rf_pred_y)\n\nprint(\"Confusion Matrix:\")\nprint(rf_cm)\nprint(\"Accuracy Score: {:.2f}\".format(rf_acc))\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-12-17T04:19:59.402348Z\",\"iopub.execute_input\":\"2022-12-17T04:19:59.402979Z\",\"iopub.status.idle\":\"2022-12-17T04:19:59.413436Z\",\"shell.execute_reply.started\":\"2022-12-17T04:19:59.402892Z\",\"shell.execute_reply\":\"2022-12-17T04:19:59.412496Z\"}}\n'KN accuracy'\nkn_cm = confusion_matrix(val_y, kn_pred_y)\nkn_acc = accuracy_score(val_y, kn_pred_y)\n\nprint(\"Confusion Matrix:\")\nprint(kn_cm)\nprint(\"Accuracy Score: {:.2f}\".format(kn_acc))\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-12-17T04:19:59.414940Z\",\"iopub.execute_input\":\"2022-12-17T04:19:59.415290Z\",\"iopub.status.idle\":\"2022-12-17T04:19:59.429350Z\",\"shell.execute_reply.started\":\"2022-12-17T04:19:59.415246Z\",\"shell.execute_reply\":\"2022-12-17T04:19:59.428450Z\"}}\n'DT accuracy'\ndt_classifier = DecisionTreeClassifier(random_state=0)\ndt_classifier.fit(train_X, train_y) # training classifier\ndt_pred_y = dt_classifier.predict(val_X) # making prediction on validation\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-12-17T04:19:59.430656Z\",\"iopub.execute_input\":\"2022-12-17T04:19:59.430921Z\",\"iopub.status.idle\":\"2022-12-17T04:19:59.440841Z\",\"shell.execute_reply.started\":\"2022-12-17T04:19:59.430876Z\",\"shell.execute_reply\":\"2022-12-17T04:19:59.440004Z\"}}\n'KN accuracy'\ndt_cm = confusion_matrix(val_y, dt_pred_y)\ndt_acc = accuracy_score(val_y, dt_pred_y)\n\nprint(\"Confusion Matrix:\")\nprint(dt_cm)\nprint(\"Accuracy Score: {:.2f}\".format(dt_acc))\n\n# %% [markdown]\n# \n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-12-17T04:19:59.441871Z\",\"iopub.execute_input\":\"2022-12-17T04:19:59.442653Z\",\"iopub.status.idle\":\"2022-12-17T04:19:59.454218Z\",\"shell.execute_reply.started\":\"2022-12-17T04:19:59.442603Z\",\"shell.execute_reply\":\"2022-12-17T04:19:59.453294Z\"}}\nacc = 0\ncount = 0\nfor a,b,c,d in zip(dt_pred_y,kn_pred_y,rf_pred_y, val_y):\n    count+=1\n    if np.sum([a,b,c]) >= 2: \n        p = 1\n        #print(p, d)\n        if p == d:\n            acc+=1\n    else: \n        p = 0\n        #print(p, d)\n        if p==d:\n            acc+=1\nprint(acc/count)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-12-17T04:19:59.455676Z\",\"iopub.execute_input\":\"2022-12-17T04:19:59.455983Z\",\"iopub.status.idle\":\"2022-12-17T04:19:59.523821Z\",\"shell.execute_reply.started\":\"2022-12-17T04:19:59.455943Z\",\"shell.execute_reply\":\"2022-12-17T04:19:59.522848Z\"}}\nimport joblib\n# save RF\njoblib.dump(rf_classifier, \"./random_forest.joblib\")\n# save DT\njoblib.dump(dt_classifier, \"./decision_tree.joblib\")\n# save KN\njoblib.dump(kn_classifier, \"./k_neighbours.joblib\")\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-12-17T04:19:59.525157Z\",\"iopub.execute_input\":\"2022-12-17T04:19:59.525482Z\",\"iopub.status.idle\":\"2022-12-17T04:19:59.574045Z\",\"shell.execute_reply.started\":\"2022-12-17T04:19:59.525441Z\",\"shell.execute_reply\":\"2022-12-17T04:19:59.572992Z\"}}\n'example how to load pre-trained models'\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nimport joblib\ndt_classifier = DecisionTreeClassifier(random_state=0)\nkn_classifier = KNeighborsClassifier(n_neighbors=3)\nrf_classifier = RandomForestClassifier(random_state=0)\n\nrf_classifier = joblib.load('/kaggle/working/random_forest.joblib')\nkn_classifier = joblib.load('/kaggle/working/k_neighbours.joblib')\ndt_classifier = joblib.load('/kaggle/working/decision_tree.joblib')\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-12-17T04:40:12.619715Z\",\"iopub.execute_input\":\"2022-12-17T04:40:12.620034Z\",\"iopub.status.idle\":\"2022-12-17T04:40:12.662919Z\",\"shell.execute_reply.started\":\"2022-12-17T04:40:12.619997Z\",\"shell.execute_reply\":\"2022-12-17T04:40:12.661956Z\"}}\n#from link.csv file to know which major as the input of the model\nval_X_df = pd.read_csv('val_X.csv')\nlist_df = pd.read_csv('link.csv')\n\n\nval_X_df.set_axis(['id', 'Interval 1', 'Interval 2','Interval 3', 'Interval 4', 'Interval 4_1', 'Interval 5_1', 'Interval 6_1'], axis='columns', inplace=True)\nprint(val_X_df)\n\nlist_df.set_axis(['id', 'File Name'], axis='columns', inplace=True)\nprint(list_df)\n\n#check for the first row of the validationX:\nprint(val_X_df.id)\n\nwav_file_name = '0'\nfor i in range(len(list_df)):\n    if val_X_df.id[0] == list_df.id[i]:\n        wav_file_name = list_df['File Name'][i]\n        break\n\nchord_type = wav_file_name[0:5]\nIPython.display.Audio('../input/musical-instrument-chord-classification/Audio_Files/' + chord_type + '/' + list_df['File Name'][i], rate = 44100)\n\n# %% [code]\n","metadata":{"_uuid":"ca5d9708-3063-4d74-9103-131deac24d8c","_cell_guid":"8b326011-2a18-4b92-ad7f-25dbc5d015d6","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}